\section{Challenges with \cct{}}
\label{challenges}
Code completion tools are very useful, but are often limited to the generation of single elements (e.g. method calls and properties) and the usage of templates. Furthermore, too many recommendations can decrease the usefulness of the tool~\cite{Proksch2015}. 
Some of these basic programming challenges have been already documented and are, we suspect, very much under consideration by the corporate teams behind Copilot and Codex. Since these tools are trained on existing software source code, and training costs are expensive, several classes of errors have been discovered, which follow from the presence of these same errors in public (training) data.

Copilot can make simple coding mistakes, such as not allowing for an empty array in a sort routine\footnote{all examples are documented in our \repl{}.}. Copilot does not understand security vulnerabilities, so it will suggest code that allows for a \textsf{log4shell} vulnerability\footnote{\url{https://www.wiz.io/blog/10-days-later-enterprises-halfway-through-patching-log4shell/}}, or common SQL injection attacks. A recent study by Pearce et al.~\cite{copilot_security} showed that approximately 40\% of the code suggested by Copilot is found to be vulnerable, when tested on 89 different scenarios for Copilot to complete.
Similarly, concerns have been raised about Copilot licence compliance and copyright violation~\cite{code_clone}; with similar input data, Copilot suggests identical code to existing code on GitHub, which may be under copyright. 

% Karampatsis et al.~\cite{github_bugs} showed that for the 1000 most popular open-source Java repositories on GitHub, there is a frequency of one single statement bug per 1600-2500 lines of code and about 33\% of all the bugs match a set of 16 bug templates. This shows that there are bugs which occur repeatedly in the public repositories of GitHub, which can make Copilot biased to suggest bug prone code over bug-free versions.
As it is trained on public data collected in May 2020 from 50 million public repositories on GitHub~\cite{copilot}, any code uploaded after that date is absent in the knowledge base of Copilot. 
% The training data for Copilot was collected in May 2020 from 50 million public repositories on GitHub~\cite{copilot}. 
%It does not have any data uploaded to GitHub after that date and any data from useful sources like documentation and Stack Overflow to improve its suggestions from commonly occurring bugs.
Any software flaws present in large numbers on GitHub will tend to dominate the learning of the model.

But these challenges are not surprising, and have straightforward fixes. These Fixes might include better data engineering and filtering, to remove known problems like a filter that was introduced by GitHub to suppress Copilot suggestions containing code that matches public code on GitHub, although the exact filtering process has not been publicly disclosed.
Similarly, it seems viable to conduct security scans or linting runs prior to making a suggestion, in order to remove obvious problems like SQL injection. 
Clone detection techniques can help find places where code violates copyright. 
Better machine learning approaches, using active learning or fine-tuning, might help learn local lessons~\cite{Menzies2013} for customization in the case of identifier naming or formatting.
In most of these cases, good tools exist already for this. 

Our belief is that while heuristic, such flaws can be fixed and will be fixed in short order. 
What we believe is harder to fix will be problems where straight-forward corrections may not exist and rules for finding problems are harder to specify than those in smell detectors or linters~\cite{Ernst2017} like language idioms and code smells.
