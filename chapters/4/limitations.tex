\section{Limitations}
Access to Copilot

Copilot is very sensitive to input. This hurts replicability as a different formulation of the problem might well produce a totally different set of suggestions. 
Thus a reasonable concern is that our (human) input is unfair to Copilot, and with some longer suggestions, the tool would generate the correct idiom. \neil{can we try this? }\rohith{idioms are mostly one lined, and longer inputs/suggestions could be described as bad practices/design smells}
Our intention is admittedly to show where Copilot is not able to consistently generate the preferred answer. We biased our evaluation to highlight this by choosing input that simulates what a less experienced programmer might choose. But this is reasonable: for one, these are precisely the developers likely to use Copilot suggestions, and unlikely to know the idiomatic usage; more importantly, a lack of suggestion stability seems to come with its own set of challenges (to use an analogy, we would expect every Tesla to make the same choice when confronted with the same circumstances). %this gets to the top levels of Koopmann's pyramid.

Working with GitHub's API - not open

OpenAI and open source

Ethics about suggestions - different when suggestions are much broader e.g. what sort algorithm to use. Not just a technical question and much more challenging ethically than flash fill. 
