\startchapter{Discussion, Limitations and Implications}
\label{chapter:eval}

Although, copilot is very good at solving LeetCode problems~\cite{empirical_eval}, our experiments show that it does not do well in suggesting popular idioms and best practices. Based on our experiences, we suggest the following implications for future.

\section{Implications for practice}
There is a requirement for better training data to improve copilot suggestions to minimise code smells and bad practices with adding more verified sources like well known books and code documentation pages to follow the best practices. The goal here is to make good practices more frequent than the bad ones to make copilot suggest good code as its top suggestion.

code completion tools should further look into collaborating with existing tools for code smells like SonarQube\footnote{https://www.sonarqube.org} or any other code review bots, to potentially improve the quality of training data.

% As code completion tools are used for productivity, they should improve the ranking system to make best solutions appear as top suggestion (it would take more time to go through all suggestions)

Recommendations to improve AI driven Development:
\begin{enumerate}
    \item add more verified sources like books and documentations to training data.
    \item perform code smell detection and vulnerability checks before every suggestion and rank them accordingly.
    \item ranking suggestions based on repository (source of suggestion) popularity.
\end{enumerate}

\section{Implications for research}
To solve complex software engineering challenges with AI driven Development, it should capture design and module level concerns like recapturing patterns and strategies to improve and personalize suggestions. A data set with common patterns and best practices is required to train and test AI and make them capable of suggesting patterns like MVC when prompted.

Though the actual input size for context is not disclosed by copilot, There is a need to increase the input size to multiple files and folders to improve suggestions. For example, when there are multiple files implementing MVC pattern, copilot should never suggest code where model communicates directly with views.

\subsection{Explainability}---Copilot is closed source, and it is currently not possible to determine the source or the reason behind each suggestion, making it difficult to detect any problems (access is only via an API). 
However, engineering software systems is laden with ethical challenges, and understanding why a suggestion was made, particularly for architectural questions such as system fairness, is essential. 

One suggestion is to use recent ML advances in helping language models `reason', such as the chain of thought process by Wang et al.~\cite{chain_of_thought}. 
Chain-of-thought shows the model an example of reasoning, which then allows the model to reproduce the reasoning pattern on a different input.
Such reasoning is common for design questions. 
For example, using architectural scenarios helps (humans) reason about which tactic is most suitable for the scenario~\cite{kazman98}. This is a version of chain of thought for designing systems. 
However, we have an imperfect understanding of the strategies that drive human design approaches for software~\cite{Arab2022}. 
% to improve the reasoning ability and also inform the user about the process behind the creation of suggestion.

Another challenge is understanding the basis for the ranking metric for different suggestions made by Copilot. This metric has not been made public. Thus, we cannot determine the reason Copilot is ranking one approach (e.g., non-idiomatic) over the idiomatic (preferred) approach. However, large language model suggestions are based on its training data~\cite{training_extraction}, so one explanation is that the non-idiomatic approach is more frequent in the training data~\cite{stochastic_parrots}. Better characterization of the rankings would allow users to better understand the motivation. 

\subsection{Control}---Being generative models, tools like Copilot are extremely sensitive to input with stability challenges and to make them autonomous raises control concerns.
For example, if a human asks for a N\textsuperscript{2} search algorithm, should Copilot recommend one? 
Ideally, tools should warn users if prompted to suggest sub-optimal code. 
AI supported Software engineering should learn to differentiate between optimal and sub-optimal code. 
One direction to look at is following commit histories of files, as they are the possible places to find bug fixes and performance improvements.


% 	AI for design and module level concerns - how to recapture patterns and strategies
% 	Example: design a system that uses Amazon SMS to parse messages of this type and stores the data in this block store after running a lambda function to restrict access
% 	Create a website that has customers and orders and allows new orders and customer updates using MVC
% - Learn from code scans (reinforcement learning for code) 

\input{chapters/5/limitations}
\input{chapters/5/summary}