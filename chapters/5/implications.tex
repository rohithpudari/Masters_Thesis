\section{Implications}
\label{implications}
% Practical implications can be separated into two categories, pre-training and at suggestion time. 
This research helps guide future \cct{} to support software development. 
Good \cct{} has many potential uses, from recommending expanded code completions to optimizing code blocks. Automating code production could increase the productivity of current programmers. 

Future code generation models may enable developers to work at a higher degree of abstraction that hides specifics, similar to how contemporary software engineers no longer frequently write in assembly.
Good \cct{} may improve accessibility to programming or aid in training new programmers. Models could make suggestions for different, more effective, or idiomatic methods to implement programs, enabling one to develop their coding style.

\subsection{Implications for practitioners}

\subsubsection{Pre-training the LLM}
For pre-training the LLM~(e.g., Codex), 
\AISE{} tools will need higher-quality training data. This might be addressed by carefully engineering training examples and filtering out known flaws, code smells, and bad practices. Careful data curation seems to be part of the approach already~\cite{alphacode}. However, there is little clarity on how this process happens and how to evaluate suggestions, particularly for non-experts. One approach is to add more verified sources like well-known books and code documentation pages to follow the best practices. 
Pre-training might rank repositories for training input according to code quality (e.g., only repositories with acceptable coding standards).
%The goal here is to make good practices more frequent than the bad ones to make Copilot suggest good code as its top suggestion.

\subsubsection{code completion time}
% For \emph{code completion time}, 
\AISE{} tools could collaborate with, or be used in conjunction with, existing tools for code smells like SonarQube\footnote{https://www.sonarqube.org} or other code review bots to potentially improve the quality of suggestions. Since developers expect to wait for a code suggestion, the results could be filtered for quality. 
Amazon's code completion tool `CodeWhisperer' comes with a `run security scan' option, which performs a security scan on the project or file that is currently active in VS Code~\cite{amazon}.
Active learning approaches which learn a user's context (e.g., the company coding style) would also improve suggestion acceptability. %Many of these insights can be taken from existing knowledge in the information retrieval domain. 

% As code completion tools are used for productivity, they should improve the ranking system to make best solutions appear as top suggestion (it would take more time to go through all suggestions)
% Recommendations to improve \AIDE{}:
% \begin{enumerate}
%     \item add more verified sources like books and documentations to training data.
%     \item perform code smell detection and vulnerability checks before every suggestion and rank them accordingly.
%     \item ranking suggestions based on repository (source of suggestion) popularity.
% \end{enumerate}

\subsubsection{Over-reliance}
Over-reliance on generated outputs is one of the main hazards connected to the use of code generation models in practice.
Codex may provide solutions that seem reasonable on the surface but do not truly accomplish what the user had in mind. Depending on the situation, this could negatively impact inexperienced programmers and have serious safety consequences. Human oversight and vigilance are always required to safely use \cct{} like Copilot.
Empirical research is required to consistently ensure alertness in practice across various user experience levels, UI designs, and tasks.

\subsubsection{Ethical Considerations}
\label{ethics}
Packages or programs created by third parties are frequently imported within a code file. Software engineers rely on functions, libraries, and APIs for the majority of what called as ``boilerplate" code rather than constantly recreating the wheel. 
However, there are numerous choices for each task: For machine learning, use PyTorch or TensorFlow; for data visualization, use Matplotlib or Seaborn; etc.

Reliance on import suggestions from \cct{} like Copilot may increase as they get used to using \cct{}. 
Users may employ the model as a decision-making tool or search engine as they get more adept at "prompt engineering" with Codex. 
Instead of searching the Internet for information on "which machine learning package to employ" or "the advantages and disadvantages of PyTorch vs. Tensorflow," a user may now type "\# import machine learning package" and rely on Codex to handle the rest.
Based on trends in its training data, Codex imports substitutable packages at varying rates~\cite{copilot}, which may have various effects. 
Different import rates set by Codex may result in subtle mistakes when a particular import is not advised, increased robustness when an individual's alternative package would have been worse, and/or an increase in the dominance of an already powerful group of people and institutions in the software supply chain.

As a result, certain players may solidify their position in the package market, and Codex may be unaware of any new packages created following the first collection of training data. The model may also recommend deprecated techniques for packages that are already in use. Additional research is required to fully understand the effects of code creation capabilities and effective solutions.

% Despite the fact that many packages are free, developers and companies with popular packages can earn incentives, and free packages can act as covers for paid items. 
% Therefore, the import patterns used by Codex and other code generation models may have significant economic effects on individuals who create and maintain packages, in addition to possible safety or security effects.

\subsection{Implications for researchers}
With a wide range of applications, including programming accessibility, developer tools, and computer science education, effective code generation models have the potential to have a positive, revolutionary effect on society. 
However, like most technologies, these models may enable applications with societal drawbacks that we need to watch out for, and the desire to make a positive difference does not, in and of itself, serve as a defense against harm.
One challenge researchers should consider is that as capabilities improve, it may become increasingly difficult to guard against “automation bias.”

\subsubsection{Moving Beyond Tokens}
\label{tokens}
Another research challenge is to move beyond token-level suggestions and work at the code block or file level (e.g., a method or module). 
Increasing the model input size to span multiple files and folders would improve suggestions. For example, when there are multiple files implementing the MVC pattern, Copilot should never suggest code where \textsf{Model} communicates directly with \textsf{View}. 
\AISE{} tools will need to make suggestions in multiple program units to accommodate these more abstract design concerns.

One suggestion is to use recent ML advances in helping language models `reason', such as the chain of thought process by Wang et al.~\cite{chain_of_thought}. 
Chain-of-thought shows the model and example of reasoning, allowing the model to reproduce the reasoning pattern on a different input.
Such reasoning is common for design questions. 
Shokri~\cite{shokri21} explored this with framework sketches.

For example, using architectural scenarios helps (humans) reason about which tactic is most suitable for the scenario~\cite{kazman98}. This is a version of the chain of thought for designing systems. 
However, we have an imperfect understanding of the strategies that drive human design approaches for software~\cite{Arab2022}. 